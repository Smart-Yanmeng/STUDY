{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.1"
   ],
   "id": "aab9c9c7bb30cce6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = np.array([\n",
    "    10, 11, 12, 13, 14,\n",
    "    15, 16, 17, 18, 19\n",
    "])\n",
    "y = np.array([\n",
    "    0, 1, 2, 3, 4,\n",
    "    5, 6, 7, 8, 9\n",
    "])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ],
   "id": "3098d809c01f9f80"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.2"
   ],
   "id": "adea9a422034f214"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = np.array([[2, 2, -1],\n",
    "              [1, 2, -2],\n",
    "              [0, -2, 2]])\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_processing = scaler.fit_transform(X)\n",
    "print(X_processing)"
   ],
   "id": "e6c4562c0dc281dc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.3"
   ],
   "id": "781ed4f913d17d8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = np.array([[2, 2, -1],\n",
    "              [1, 2, -2],\n",
    "              [0, -2, 2]])\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_processing = scaler.fit_transform(X)"
   ],
   "id": "9d82f2989fdcdaf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.4"
   ],
   "id": "ccb55948bdddd81f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, 168, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "data.duplicated()\n",
    "print(data)\n",
    "# 查询重复列\n",
    "print(data[data.duplicated()])\n",
    "data.drop_duplicates(subset='学号', inplace=True)\n",
    "# data.drop_duplicates(['学号'],'first',inplace=True)\n",
    "print(data)"
   ],
   "id": "675a6fbf4b77f8ae"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.5"
   ],
   "id": "e4ddc0038f7ac2d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "# 删除学号 5\n",
    "data = data.dropna()\n",
    "print(data)\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "# # 传入这个参数后将只丢弃全为缺失值的那些行\n",
    "data = data.dropna(how='all')\n",
    "print(data, '---all')\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "# 丢弃有缺失值的列（一般不会这么做，这样会删掉一个特征）\n",
    "data.dropna(axis=1)\n",
    "print(data, '--1')"
   ],
   "id": "a2e2e7cf02a4c4f7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.6"
   ],
   "id": "4cef5de39b64e571"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "data = data.fillna(170)\n",
    "print(data)\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "# 表示用前面行/列的值,填充当前行/列的空值\n",
    "data = data.fillna(method='ffill')\n",
    "print(data, '--ffill')\n",
    "# bfill，则相反\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "data = data.fillna(method='bfill')\n",
    "print(data, '--bfill')\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, np.nan, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "data['身高'].fillna(data['身高'].mean(), inplace=True)\n",
    "print(data)"
   ],
   "id": "79c899f7347f7e9e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.7"
   ],
   "id": "bd78bff65e4f95ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, 1700, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "print(\"是否存在超出正常身高范围的值：\", any(data['身高'] > 240))\n",
    "renew_value = data['身高'][data['身高'] < 200].max()\n",
    "print(renew_value, '---renew_value')\n",
    "# 超过 200cm用 renew_value替代\n",
    "data.loc[data['身高'] > 200, '身高'] = renew_value\n",
    "print(data)"
   ],
   "id": "5dc401fa0f894e73"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.8"
   ],
   "id": "1cdf3f9608920566"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    '学号': [1, 2, 3, 4, 5, 6, 7, 7, 8],\n",
    "    '身高': [172, 162, 175, 170, 17, 160, 164, 164, 160],\n",
    "    '体重': [70, 62, 75, 68, 67, 58, 64, 64, 53]\n",
    "})\n",
    "print(\"是否存在低于正常身高范围的值：\", any(data['身高'] < 50))\n",
    "renew_value = data['身高'][data['身高'] > 50].min()\n",
    "print(renew_value, '---renew_value')\n",
    "data.loc[data['身高'] < 50, '身高'] = renew_value\n",
    "print(data)"
   ],
   "id": "5605ba0cac2f14bd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.9"
   ],
   "id": "7938b5bbda0f24e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = np.array([\n",
    "    [1, 2, 1, 2],\n",
    "    [7, 2, 2, 4],\n",
    "    [3, 7, 3, 6],\n",
    "    [2, 5, 2, 3],\n",
    "    [3, 2, 2, 9],\n",
    "    [5, 0, 3, 5]])\n",
    "print(X)\n",
    "# pca=PCA(n_components=3)\n",
    "pca = PCA(n_components=0.78)\n",
    "\n",
    "X_pca = pca.fit_transform(X)  #等价于pca.fit(X)pca.transform(X)\n",
    "print(X_pca, '---X_pca')\n",
    "X_new = pca.inverse_transform(X_pca)  #将降维后的数据转换成原始数据\n",
    "# #属性explained_variance_ratio_，查看降维后每个新特征向量所占的信息量占原始数据总信息量的百分比\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(X_new)"
   ],
   "id": "e0df4fdbbe226aba"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码2.10"
   ],
   "id": "7c2dec0a54d2d01f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = np.array([[10001, 2, 55], [16020, 4, 11], [12008, 6, 33], [13131, 8, 22]])\n",
    "print(x)\n",
    "# feature normalization (feature scaling)\n",
    "X_scaler = StandardScaler()\n",
    "print(X_scaler, '---X_scaler')\n",
    "x = X_scaler.fit_transform(x)\n",
    "print(x, '---x_X_scaler')\n",
    "# PCA\n",
    "pca = PCA(n_components=0.9)  # 保证降维后的数据保持90%的信息\n",
    "pca.fit(x)\n",
    "print(pca.explained_variance_ratio_)\n",
    "pca.transform(x)\n"
   ],
   "id": "12d60aeb9210b9cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：读取并显示图片\n",
    "from sklearn.datasets import load_sample_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img1 = load_sample_image(\"china.jpg\")\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "# 机器学习模型对数值小的数处理得比较好，比如CNN\n",
    "img1 = np.array(img1, dtype=np.float64) / 255\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "#第二步：图像灰度化\n",
    "from skimage import color, filters\n",
    "\n",
    "img1 = color.rgb2gray(img1)\n",
    "print(img1, '--img1')\n",
    "img2 = np.random.normal(img1.data, 0.1)\n",
    "print(img2, '--img2')\n",
    "plt.imshow(img2, cmap='gray')\n",
    "plt.show()\n",
    "#第三步：PCA降维去噪\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.88)\n",
    "img2_pca = pca.fit_transform(img2)\n",
    "img3 = pca.inverse_transform(img2_pca)\n",
    "#第四步：显示去噪后图像\n",
    "plt.imshow(img3, cmap='gray')\n",
    "plt.show()"
   ],
   "id": "5c46022e01741f5a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1"
   ],
   "id": "67ea74091ecd3678"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "print(X, '---X')\n",
    "print(X.shape)\n",
    "print(y, '---y')\n",
    "print(len(y))\n",
    "#第二步：引入时间计时\n",
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "#第三步：进行K-means聚类\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KM = KMeans(n_clusters=10)\n",
    "c = KM.fit_predict(X)\n",
    "print(c, '----c')\n",
    "end = time.process_time()\n",
    "print('Time is %.3f' % (end - start))\n",
    "#第四步：计算聚类结果\n",
    "import numpy as np\n",
    "\n",
    "# np.zeros_like 创建一个新数组,其形状和类型与给定数组相同,但是所有元素都被设置为 0\n",
    "y_predict = np.zeros_like(c)\n",
    "print(y_predict, '---y_predcit')\n",
    "from scipy.stats import mode\n",
    "\n",
    "for i in range(10):\n",
    "    mask = (c == i)\n",
    "    y_predict[mask] = mode(y[mask])[0]\n",
    "print(y_predict, '---mask_y_predcit')\n",
    "KM.cluster_centers_.shape\n",
    "#第五步：显示聚类中心\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n",
    "centers = KM.cluster_centers_.reshape(10, 8, 8)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, cmap=plt.cm.binary)\n",
    "#第六步：输出聚类准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('聚类准确率为： %.4f %%' % accuracy_score(y, y_predict))\n"
   ],
   "id": "46e0d928a9d240af"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.2"
   ],
   "id": "8533ea6cd3412d02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data;\n",
    "y = digits.target\n",
    "#第二步：引入时间计时\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "start = time.process_time()\n",
    "#第三步：PCA降维\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X)\n",
    "X_reduction = pca.transform(X)\n",
    "print(X_reduction.shape)\n",
    "end = time.process_time()\n",
    "print('PCA Time is %.3f' % (end - start))\n",
    "#第四步：K-means聚类\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "start = time.process_time()\n",
    "KM = KMeans(n_clusters=10)\n",
    "c = KM.fit_predict(X_reduction)\n",
    "end = time.process_time()\n",
    "print('K-means Time is %.3f' % (end - start))\n",
    "#第五步：计算聚类结果\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "y_predict = np.zeros_like(c)\n",
    "for i in range(10):\n",
    "    mask = (c == i)\n",
    "    y_predict[mask] = mode(y[mask])[0]\n",
    "#第六步：输出聚类准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('聚类准确率为： %.4f %%' % accuracy_score(y, y_predict))"
   ],
   "id": "ccfaa8a9a01d198a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.3"
   ],
   "id": "d46624e3080fa321"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "digits = fetch_openml('mnist_784')\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "#第二步：引入时间计时\n",
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "#第三步：K-means聚类\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KM = KMeans(n_clusters=10)\n",
    "c = KM.fit_predict(X)\n",
    "end = time.process_time()\n",
    "print('Time is %.3f' % (end - start))\n",
    "#第四步：计算聚类结果\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "y_predict = np.zeros_like(c)\n",
    "for i in range(10):\n",
    "    mask = (c == i)\n",
    "    y_predict[mask] = mode(y[mask])[0]\n",
    "#第五步：显示聚类结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n",
    "centers = KM.cluster_centers_.reshape(10, 28, 28)\n",
    "for axi, center in zip(ax.flat, centers):\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.imshow(center, cmap=plt.cm.binary)\n",
    "import pandas as pd\n",
    "\n",
    "y = y.astype(np.int8)\n",
    "y_predict = pd.DataFrame(y_predict)\n",
    "y_predict = y_predict.astype(np.int8)\n",
    "#第六步：输出聚类准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('聚类准确率为： %.4f %%' % accuracy_score(y, y_predict))"
   ],
   "id": "2ca2053c55c55186"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.4"
   ],
   "id": "4aa5abd4d5d11b46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "digits = fetch_openml('mnist_784')\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "#第二步：PCA降维\n",
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=64)\n",
    "pca.fit(X)\n",
    "X_reduction = pca.transform(X)\n",
    "print(X_reduction.shape)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KM = KMeans(n_clusters=10)\n",
    "c = KM.fit_predict(X_reduction)\n",
    "end = time.process_time()\n",
    "print('Time is %.3f' % (end - start))\n",
    "#第四步：计算聚类结果\n",
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "y_predict = np.zeros_like(c)\n",
    "for i in range(10):\n",
    "    mask = (c == i)\n",
    "    y_predict[mask] = mode(y[mask])[0]\n",
    "#第五步：显示聚类结果\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = y.astype(np.int8)\n",
    "import pandas as pd\n",
    "\n",
    "y_predict = pd.DataFrame(y_predict)\n",
    "y_predict = y_predict.astype(np.int8)\n",
    "accuracy_score(y, y_predict)"
   ],
   "id": "c7db3f930f3a8a0b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.5"
   ],
   "id": "7bae8d9c3dbfe269"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([\n",
    "    159.3, 160.3, 165.2, 162.5,\n",
    "    175.4, 178.6, 177.1, 176.4,\n",
    "    189.4, 176.2, 185.3, 161.3,\n",
    "    164.2, 163.5, 176.4, 185.6,\n",
    "    175.1, 168.4, 187.4, 185.2\n",
    "])\n",
    "y = np.array([\n",
    "    60.5, 60.2, 60.4, 62.1,\n",
    "    75.1, 75.3, 78.2, 75.4,\n",
    "    85.8, 73.7, 81, 62.2,\n",
    "    64.4, 65.1, 75.1, 85.3,\n",
    "    78, 60.4, 80.8, 79.7\n",
    "])\n",
    "#第二步：显示二维数据\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.scatter(x, y)\n",
    "plt.xlim([150, 190])\n",
    "plt.ylim([45, 90])\n",
    "plt.xlabel('身高（cm）')\n",
    "plt.ylabel('体重（kg）')\n",
    "plt.show()"
   ],
   "id": "572a96daa7d795ac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.6"
   ],
   "id": "64b1d41c870112b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([\n",
    "    159.3, 160.3, 165.2, 162.5,\n",
    "    175.4, 178.6, 177.1, 176.4,\n",
    "    189.4, 176.2, 185.3, 161.3,\n",
    "    164.2, 163.5, 176.4, 185.6,\n",
    "    175.1, 168.4, 187.4, 185.2\n",
    "])\n",
    "y = np.array([\n",
    "    60.5, 60.2, 60.4, 62.1,\n",
    "    75.1, 75.3, 78.2, 75.4,\n",
    "    85.8, 73.7, 81, 62.2,\n",
    "    64.4, 65.1, 75.1, 85.3,\n",
    "    78, 60.4, 80.8, 79.7\n",
    "])\n",
    "X = np.array(list(zip(x, y))).reshape(len(x), 2)\n",
    "K = range(1, 10)\n",
    "meandistortions = []\n",
    "#第二步：肘部法则\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    meandistortions.append(sum(np.min(cdist(X, kmeans.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "#第三步：输出结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.plot(K, meandistortions, 'bx-')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('平均离差')\n",
    "plt.title('用肘部法则选取K值')\n",
    "plt.show()"
   ],
   "id": "472333835cb31342"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.7"
   ],
   "id": "5c0b5a2407e96a77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([\n",
    "    159.3, 160.3, 165.2, 162.5,\n",
    "    175.4, 178.6, 177.1, 176.4,\n",
    "    189.4, 176.2, 185.3, 161.3,\n",
    "    164.2, 163.5, 176.4, 185.6,\n",
    "    175.1, 168.4, 187.4, 185.2\n",
    "])\n",
    "y = np.array([\n",
    "    60.5, 60.2, 60.4, 62.1,\n",
    "    75.1, 75.3, 78.2, 75.4,\n",
    "    85.8, 73.7, 81, 62.2, 64.4,\n",
    "    65.1, 75.1, 85.3, 78,\n",
    "    60.4, 80.8, 79.7\n",
    "])\n",
    "sc_scores = []\n",
    "X = np.array(list(zip(x, y))).reshape(len(x), 2)\n",
    "#第二步：轮廓系数法\n",
    "clusters_number = [2, 3, 4, 6, 7, 8]\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "for t in clusters_number:\n",
    "    kmeans_model = KMeans(n_clusters=t).fit(X)\n",
    "    sc_scores.append(silhouette_score(X, kmeans_model.labels_, metric='euclidean'))\n",
    "#第三步：输出结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.xlabel('K-簇数量')\n",
    "plt.ylabel('轮廓系数')\n",
    "plt.plot(clusters_number, sc_scores, 'o-')"
   ],
   "id": "2c51b3981b24a081"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码3.8"
   ],
   "id": "e0827b64edcbbffb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：读取并显示图片\n",
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "img1 = load_sample_image(\"china.jpg\")\n",
    "import numpy as np\n",
    "\n",
    "img1 = np.array(img1, dtype=np.float64) / 255\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "m, n, p = img1.shape;\n",
    "x = img1.reshape(-1, p)\n",
    "print(img1.shape, x.shape)\n",
    "#第二步：进行颜色级聚类\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "colors = 20\n",
    "KM = KMeans(colors)\n",
    "labels = KM.fit_predict(x)\n",
    "color = KM.cluster_centers_\n",
    "\n",
    "\n",
    "#第三步：进行颜色级替换\n",
    "def recreate_img1(codebook, labels, m, n, p):\n",
    "    img1 = np.zeros((m, n, p))\n",
    "    label_idx = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            img1[i][j] = codebook[labels[label_idx]]\n",
    "            label_idx += 1\n",
    "    return img1\n",
    "\n",
    "\n",
    "#第四步：重构图片\n",
    "img2 = recreate_img1(KM.cluster_centers_, labels, m, n, p)\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "num = np.unique(img1.reshape(-1, 1))"
   ],
   "id": "6d00ba5786b0b223"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码4.1"
   ],
   "id": "15d82a06e51673d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "#第二步：PCA降维\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA_X = PCA(n_components=2)\n",
    "reduced_X = PCA_X.fit_transform(X)\n",
    "#第三步：对降维后的数据进行二维可视化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(reduced_X[y == 0, 0], reduced_X[y == 0, 1], color='r', marker='D')\n",
    "plt.scatter(reduced_X[y == 1, 0], reduced_X[y == 1, 1], color='g', marker='+')\n",
    "plt.scatter(reduced_X[y == 2, 0], reduced_X[y == 2, 1], color='b', marker='x')"
   ],
   "id": "7361a3688a967406"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码4.2"
   ],
   "id": "9fcb547dea695c46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "load_data = load_iris()\n",
    "x = load_data.data\n",
    "y = load_data.target\n",
    "print(x[:10])\n",
    "#第二步：数据集划分并标准化\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "x_train = std.fit_transform(x_train)\n",
    "x_test = std.transform(x_test)\n",
    "#第三步：KNN训练并预测\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "result = knn.predict(x_test)\n",
    "#第四步：输出结果\n",
    "r_result = knn.score(x_test, y_test)\n",
    "print(\"训练的结果为：\", result)\n",
    "print(\"正确的结果为：\", y_test)\n",
    "print(\"识别成功率为：\", r_result)\n",
    "# 预测花萼长5cm宽3cm 花瓣长1cm宽0.5cm品种\n",
    "X_new = np.array([[5, 3, 1, 0.5]])\n",
    "prediction = knn.predict(X_new)\n",
    "print(\"这个鸢尾花的品种为：{}\".format(load_data['target_names'][prediction]))\n"
   ],
   "id": "d889dd646a191e09"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码4.3"
   ],
   "id": "b8282c1ad890a079"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [182, 80, 1],\n",
    "    [177, 70, 1],\n",
    "    [160, 59, 0],\n",
    "    [154, 54, 0],\n",
    "    [165, 65, 1],\n",
    "    [192, 90, 1],\n",
    "    [174, 64, 0],\n",
    "    [176, 70, 0],\n",
    "    [158, 54, 0],\n",
    "    [172, 76, 1]\n",
    "])\n",
    "y = [44, 43, 38, 37, 40, 47, 39, 40, 37, 42]\n",
    "k = 5\n",
    "#第二步：KNN训练\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(k)\n",
    "knn.fit(X, y)\n",
    "#第三步：数据预测\n",
    "X_test = np.array([\n",
    "    [174, 59, 0],\n",
    "    [174, 75, 1]\n",
    "])\n",
    "predictions = knn.predict(X_test)\n",
    "print(\"预测的鞋号为：\", predictions)\n"
   ],
   "id": "60f5ee2d6fbebf7a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码4.4"
   ],
   "id": "5247ab7b7c4c5195"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn import datasets\n",
    "\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "#第二部：数据集划分\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=1 / 3, random_state=3)\n",
    "#第三步：选择模型进行K折交叉验证\n",
    "k_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
    "cv_scores = []\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for n in k_range:\n",
    "    knn = KNeighborsClassifier(n)\n",
    "    scores = cross_val_score(knn, train_X, train_y, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    print(\"当前的准确率为 :%.2f\" % scores.mean(), \"当前K的取值为 :%d\" % n)\n",
    "#第四步：结果显示\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(k_range, cv_scores)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ],
   "id": "5902d23163ab6764"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码5.1"
   ],
   "id": "8dc703c63d791294"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [1], [2], [5], [6], [7], [8], [9], [14], [15], [16], [24]\n",
    "])\n",
    "Y = [1, 2, 3, 2.5, 3, 4.9, 6.5, 8.7, 9.5, 11, 18]\n",
    "#第二步：划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=10010)\n",
    "#第三步：显示数据点\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.scatter(x_train, y_train, label='train', color='b')\n",
    "plt.scatter(x_test, y_test, label='test', color='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "#第四步：模型训练\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(x_train, y_train)\n",
    "#第五步：显示训练点与拟合直线\n",
    "plt.scatter(x_train, y_train, color='b', label='测试数据')\n",
    "y_train_pred = LR.predict(x_train)\n",
    "plt.plot(x_train, y_train_pred, color='green', label='拟合直线')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#第六步：输出参数\n",
    "a = LR.intercept_\n",
    "b = LR.coef_\n",
    "print('拟合直线参数：a=', a, '，b=', b)"
   ],
   "id": "900562bc04f20a7e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码5.2"
   ],
   "id": "5bc0f93ac5c93d06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X, Y = boston.data, boston.target\n",
    "#第二步：数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1001)\n",
    "#第三步：模型选择、训练与预测\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "#第四步：输出结果\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(mean_squared_error(y_test, y_predict))\n",
    "print(reg.score(x_train, y_train))\n",
    "print(reg.score(x_test, y_test))\n"
   ],
   "id": "7360ba0df97f75d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码5.3"
   ],
   "id": "6c264b41ed3a5d40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：数据装载\n",
    "import numpy as np\n",
    "\n",
    "X = np.linspace(-10, 10, 400)\n",
    "Y = np.sin(X) + 0.1 * np.random.rand(len(X))\n",
    "X = X.reshape(-1, 1)\n",
    "Y = Y.reshape(-1, 1)\n",
    "#第二步：多项式扩展进行模型训练\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dim = 30\n",
    "\n",
    "\n",
    "def polynomial_LR(degree=1):\n",
    "    polynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    linear_regression = LinearRegression(normalize=True)\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features), (\"linear_regression\", linear_regression)])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = polynomial_LR(degree=dim)\n",
    "model.fit(X, Y)\n",
    "#第三步：进行预测并输出结果\n",
    "train_score = model.score(X, Y)\n",
    "mse = mean_squared_error(Y, model.predict(X))\n",
    "print(train_score)\n",
    "print(mse)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.plot(X, model.predict(X), 'r-')\n"
   ],
   "id": "16f3a4e625f6816c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码6.1"
   ],
   "id": "47ee130ed414c6c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#导入数据集\n",
    "credit_card = pd.read_csv('d:/creditcard.csv')\n",
    "#输出读取的数据\n",
    "print(credit_card.shape)\n",
    "#输出3行数据\n",
    "print(credit_card.head(3))\n"
   ],
   "id": "53e9457d923511ee"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码6.2"
   ],
   "id": "bbaf1bf273601154"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "import pandas as pd\n",
    "\n",
    "credit_card = pd.read_csv('d:/creditcard.csv')\n",
    "X = credit_card.drop(columns='Class', axis=1)\n",
    "y = credit_card.Class.values\n",
    "#第二步：数据划分及归一化\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "#第三步：模型选择与训练\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "y_train_hat = LR.predict(X_train)\n",
    "y_train_hat_probs = LR.predict_proba(X_train)[:, 1]\n",
    "#第四步：输出训练过程结果\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat) * 100\n",
    "train_auc_roc = roc_auc_score(y_train, y_train_hat_probs) * 100\n",
    "print('混淆矩阵:\\n', confusion_matrix(y_train, y_train_hat))\n",
    "print('训练 AUC: %.4f %%' % train_auc_roc)\n",
    "print('训练准确率: %.4f %%' % train_accuracy)\n",
    "#第五步：输出测试结果\n",
    "y_test_hat = LR.predict(X_test)\n",
    "y_test_hat_probs = LR.predict_proba(X_test)[:, 1]\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat) * 100\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_hat_probs) * 100\n",
    "print('混淆矩阵:\\n', confusion_matrix(y_test, y_test_hat))\n",
    "print('测试集 AUC: %.4f %%' % test_auc_roc)\n",
    "print('测试集准确率: %.4f %%' % test_accuracy)\n",
    "print(classification_report(y_test, y_test_hat, digits=6))\n"
   ],
   "id": "e448c56156a6a7c8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码6.3"
   ],
   "id": "f6345c9eb347acd0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ],
   "id": "1be575fd3c41e4e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码6.4"
   ],
   "id": "e6028cb6470cd746"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：安装所需要的库\n",
    "pip\n",
    "install\n",
    "imbalanced - learn"
   ],
   "id": "4d08fff393ba3b52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二步：导入数据集并预处理\n",
    "import pandas as pd\n",
    "\n",
    "credit_card = pd.read_csv('d:/creditcard.csv')\n",
    "X = credit_card.drop(columns='Class', axis=1)\n",
    "y = credit_card.Class.values\n",
    "#第三步：划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#第四步：定义SMOTE模型\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "OS = SMOTE(random_state=1)\n",
    "X_train, y_train = OS.fit_resample(X_train, y_train)\n",
    "#第五步：数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "#第六步：训练模型并进行预测\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "y_train_hat = LR.predict(X_train)\n",
    "y_train_hat_probs = LR.predict_proba(X_train)[:, 1]\n",
    "#第七步：输出训练过程结果\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat) * 100\n",
    "train_auc_roc = roc_auc_score(y_train, y_train_hat_probs) * 100\n",
    "print('混淆矩阵:\\n', confusion_matrix(y_train, y_train_hat))\n",
    "print('训练 AUC: %.4f %%' % train_auc_roc)\n",
    "print('训练准确率: %.4f %%' % train_accuracy)\n",
    "y_test_hat = LR.predict(X_test)\n",
    "y_test_hat_probs = LR.predict_proba(X_test)[:, 1]\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat) * 100\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_hat_probs) * 100\n",
    "print('混淆矩阵:\\n', confusion_matrix(y_test, y_test_hat))\n",
    "print('测试集 AUC: %.4f %%' % test_auc_roc)\n",
    "print('测试集准确率: %.4f %%' % test_accuracy)\n",
    "print(classification_report(y_test, y_test_hat, digits=6))"
   ],
   "id": "ae4f7943aab53c3d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码6.5"
   ],
   "id": "bebe456320acd1b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#数据集归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#训练模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(penalty='l2', C=100, multi_class='ovr')\n",
    "LR.fit(X_train, y_train)\n",
    "y_predict = LR.predict(X_test)\n",
    "#模型预测\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "print(y_test)\n",
    "print(y_predict)"
   ],
   "id": "58a3ebfda6cdfb19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码7.1"
   ],
   "id": "a2c8501ef44c11b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "# 转换为DataFrame格式\n",
    "X['target'] = data.target\n",
    "C0 = X[X['target'] == 0].values\n",
    "C1 = X[X['target'] == 1].values\n",
    "C2 = X[X['target'] == 2].values\n",
    "#绘制三维图，其中scatter()函数表示x，y和z轴\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(C0[:, 3], C0[:, 2], C0[:, 2], label='setosa')\n",
    "ax.scatter(C1[:, 3], C1[:, 2], C1[:, 2], label='versicolor')\n",
    "ax.scatter(C2[:, 3], C2[:, 2], C2[:, 2], label='virginica')\n",
    "#显示三维图\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "eb679c593e95fcde"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码7.2"
   ],
   "id": "5eb738675972cd50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "feature_names = iris.feature_names\n",
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1024)\n",
    "#模型引入、训练、测试 \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "y_ = clf.predict(X_test)\n",
    "#计算正确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_))\n",
    "#输出结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(clf, filled=True, feature_names=feature_names)\n",
    "plt.show()\n"
   ],
   "id": "f3074c7791ef1f62"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码7.3"
   ],
   "id": "2667789e45fb7bc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "feature_names = iris.feature_names\n",
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1024)\n",
    "#模型引入、训练、测试 \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_ = clf.predict(X_test)\n",
    "#计算正确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_))\n",
    "#输出结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(clf, filled=True, feature_names=feature_names)\n",
    "plt.show()\n"
   ],
   "id": "9189a42993c5d9b9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码7.4"
   ],
   "id": "68231286e874c3ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num = 400\n",
    "X = np.linspace(-10, 10, num)\n",
    "X = X.reshape(num, 1)\n",
    "y = np.cos(X).ravel() + np.random.rand(len(X))\n",
    "#深度为2\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DTR = DecisionTreeRegressor(max_depth=2)\n",
    "DTR.fit(X, y)\n",
    "#预测过程\n",
    "X_test = np.arange(-10, 10.0, 0.01)[:, np.newaxis]\n",
    "y_predict = DTR.predict(X_test)\n",
    "#输出结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.figure()\n",
    "plt.scatter(X, y, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_predict, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.xlabel(\"输入\")\n",
    "plt.ylabel(\"输出\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "cb4b3162db5796db"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码7.5"
   ],
   "id": "997e8f43b1175b1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "X, Y = boston.data, boston.target\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "#给定标准，选取特征\n",
    "from sklearn.feature_selection import SelectPercentile, f_regression\n",
    "\n",
    "selector = SelectPercentile(f_regression, percentile=10)\n",
    "\n",
    "X_new = selector.fit_transform(X, Y)\n",
    "print(X_new.shape)\n",
    "X = X_new\n",
    "#划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=1001)\n",
    "#训练模型\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg = DecisionTreeRegressor(max_depth=8)\n",
    "reg.fit(x_train, y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "#输出预测结果\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(mean_squared_error(y_test, y_predict))\n",
    "print(reg.score(x_train, y_train))\n",
    "print(reg.score(x_test, y_test))\n"
   ],
   "id": "44e9fb1e143c7dc0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码8.1"
   ],
   "id": "c44a98669a1d3d77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "data, label = make_blobs(n_samples=100, centers=2)\n",
    "#SVC建立模型，使用样本data和label训练SVM模型\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel=\"linear\", C=1000)\n",
    "SVM.fit(data, label)\n",
    "#绘制分割后的超平面并输出样本分类结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], c=label, s=50)\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "import numpy as np\n",
    "\n",
    "xx = np.linspace(xlim[0], xlim[1], 50)\n",
    "yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "Y, X = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "Z = SVM.decision_function(xy).reshape(X.shape)\n",
    "ax.contour(X, Y, Z, levels=[-1, 0, 1])\n",
    "ax.scatter(SVM.support_vectors_[:, 0],\n",
    "           SVM.support_vectors_[:, 1],\n",
    "           s=100, linewidth=1, facecolors=\"none\")\n",
    "plt.show()\n"
   ],
   "id": "a35c287eece0916c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码8.2"
   ],
   "id": "994edee106ec6961"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip\n",
    "install\n",
    "tensorflow\n",
    "pip\n",
    "install\n",
    "matplotlib\n",
    "pip\n",
    "install\n",
    "sklearn\n"
   ],
   "id": "1ec0ae6962e92537"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "#数据集归一化\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "#标签分类\n",
    "label_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "#显示分类结果图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(label_names[y_train[i]])\n",
    "# 转换数据类型\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "#SVC建模，训练模型  \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1, kernel='linear', gamma=\"auto\")\n",
    "svc.fit(X_train_flat, y_train)\n",
    "y_pred_svc = svc.predict(X_test_flat)\n",
    "#输出分类结果\n",
    "from sklearn import metrics\n",
    "\n",
    "F1 = metrics.f1_score(y_test, y_pred_svc, average=\"weighted\")\n",
    "Accuracy = metrics.accuracy_score(y_test, y_pred_svc)\n",
    "CM = metrics.confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"准确率: {}\".format(Accuracy))\n",
    "print(\"混沌矩阵: \\n\", CM)\n",
    "print(metrics.classification_report(y_test, y_pred_svc))\n"
   ],
   "id": "9cb22e56138080"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码8.3"
   ],
   "id": "4b32bd2ee161b71e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "y[::4] += 3 * (0.5 - np.random.rand(25))\n",
    "#设置不同的核函数\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "RBF = SVR(kernel='rbf')\n",
    "RBF_clf = RBF.fit(X, y).predict(X)\n",
    "Linear = SVR(kernel='linear')\n",
    "Linear_clf = Linear.fit(X, y).predict(X)\n",
    "Poly = SVR(kernel='poly')\n",
    "Poly_clf = Poly.fit(X, y).predict(X)\n",
    "#设置不同的核函数所输出的不同预测结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y, c=\"black\")\n",
    "plt.plot(X, RBF_clf, c=\"blue\")\n",
    "plt.scatter(X, y, c=\"black\")\n",
    "plt.plot(X, Linear_clf, c=\"green\")\n",
    "plt.scatter(X, y, c=\"black\")\n",
    "plt.plot(X, Poly_clf, c=\"red\")\n"
   ],
   "id": "5a7e3b059af80143"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码8.4"
   ],
   "id": "72d0c83fb3968981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_boston()\n",
    "X = data.data\n",
    "y = data.target\n",
    "#划分数据集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.02)\n",
    "#\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Std_X = StandardScaler()\n",
    "#数据统一标准化\n",
    "Xtrain = Std_X.fit_transform(Xtrain)\n",
    "Xtest = Std_X.transform(Xtest)\n",
    "Std_y = StandardScaler()\n",
    "#获取目标值\n",
    "Ytrain = Std_y.fit_transform(Ytrain.reshape(-1, 1))\n",
    "Ytest = Std_y.transform(Ytest.reshape(-1, 1))\n",
    "#设置核函数的类型为rbf\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "RBF = SVR(kernel='rbf')\n",
    "RBF_clf = RBF.fit(Xtrain, Ytrain).predict(Xtest)\n",
    "#设置核函数的类型为linear\n",
    "Linear = SVR(kernel='linear')\n",
    "Linear_clf = Linear.fit(Xtrain, Ytrain).predict(Xtest)\n",
    "#设置核函数的类型为poly\n",
    "Poly = SVR(kernel='poly')\n",
    "Poly_clf = Poly.fit(Xtrain, Ytrain).predict(Xtest)\n",
    "#输出核函数为rbf的结果\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.mean_squared_error(Ytest, RBF_clf))\n",
    "print(RBF_clf)\n",
    "#输出核函数为linear的结果\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.mean_squared_error(Ytest, Linear_clf))\n",
    "print(Linear_clf)\n",
    "#输出核函数为poly的结果\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.mean_squared_error(Ytest, Poly_clf))\n"
   ],
   "id": "e45b7d85d999f564"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码9.1"
   ],
   "id": "80d5be3cc94b0e45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.linspace(-10, 10, 400)\n",
    "X_new = X.reshape(-1, 1)\n",
    "y = X * X + 1 * np.random.rand(len(X))\n",
    "#初始化模型对象\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "MLP = MLPRegressor(alpha=1e-6, hidden_layer_sizes=(10, 20), random_state=10, max_iter=100000, activation='relu')\n",
    "MLP.fit(X_new, y)\n",
    "y_new = MLP.predict(X_new)\n",
    "#绘制抛物线\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y, c=\"yellow\")\n",
    "plt.plot(X_new, y_new, c=\"black\")\n"
   ],
   "id": "f93b65eeec13930a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码9.2"
   ],
   "id": "bc422ac1f99a4e1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "#数据归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#训练模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(20, 8), max_iter=100000)\n",
    "MLP.fit(X_train, y_train)\n",
    "y_predict = MLP.predict(X_test)\n",
    "#输出分类结果\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "train_accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print('混淆矩阵:\\n', confusion_matrix(y_test, y_predict))\n",
    "print(train_accuracy)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n"
   ],
   "id": "bc0bdeaa2939834d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码10.1"
   ],
   "id": "1cf329818fb87b2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#建立模型，训练模型\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "Boosting = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "model = Boosting.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#输出分类结果\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"准确率为:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "9979e7c335e2a900"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码10.2"
   ],
   "id": "d1a46291242250ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#建立SVM分类模型，训练模型\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "Boosting = AdaBoostClassifier(n_estimators=50, base_estimator=svc, learning_rate=1)\n",
    "model = Boosting.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#输出分类结果\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"准确率为:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n"
   ],
   "id": "e8c04e3f6f2ed53c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码10.3"
   ],
   "id": "836188d4b9a373b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一步：装载数据\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "Data = fetch_lfw_people(min_faces_per_person=70)\n",
    "x = Data.data\n",
    "n_features = x.shape[1]\n",
    "y = Data.target\n",
    "target_names = Data.target_names\n",
    "#第二步：显示数据\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(x[i].reshape(62, 47))\n",
    "    plt.xlabel(target_names[y[i]])\n",
    "#第三步：数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)\n",
    "#第四步：对数据集进行降维处理\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA = PCA(n_components=100).fit(x_train)\n",
    "x_train_pca = PCA.transform(x_train)\n",
    "x_test_pca = PCA.transform(x_test)\n",
    "#第五步：使用knn进行分类\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_pca, y_train)\n",
    "#第六步：使用adaboost进行分类\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "Ada_DTC = AdaBoostClassifier(n_estimators=100, learning_rate=0.2)\n",
    "Ada_DTC.fit(x_train_pca, y_train)\n",
    "#第七步：使用SVC进行分类\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "Ada_SVC = AdaBoostClassifier(base_estimator=svc, n_estimators=100, learning_rate=0.2)\n",
    "Ada_SVC.fit(x_train_pca, y_train)\n",
    "#第八步：结果预测\n",
    "y_pred1 = knn.predict(x_test_pca)\n",
    "y_pred2 = Ada_DTC.predict(x_test_pca)\n",
    "y_pred3 = Ada_SVC.predict(x_test_pca)\n",
    "#第九步：输出结果\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"#################KNN人脸识别###################\")\n",
    "print(knn.score(x_test_pca, y_test))\n",
    "print(metrics.classification_report(y_test, y_pred1))\n",
    "print(metrics.confusion_matrix(y_test, y_pred1))\n",
    "print(\"########Adaboost+决策树弱分类器人脸识别#########\")\n",
    "print(Ada_DTC.score(x_test_pca, y_test))\n",
    "print(metrics.classification_report(y_test, y_pred2))\n",
    "print(metrics.confusion_matrix(y_test, y_pred2))\n",
    "print(\"##########Adaboost+SVC弱分类器人脸识别##########\")\n",
    "print(Ada_SVC.score(x_test_pca, y_test))\n",
    "print(metrics.classification_report(y_test, y_pred3))\n",
    "print(metrics.confusion_matrix(y_test, y_pred3))\n"
   ],
   "id": "709e9d62ca3d103c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码10.4"
   ],
   "id": "24239e5cd58a2811"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "第一步：装载数据\n",
    "import numpy as np\n",
    "\n",
    "X = np.linspace(-10, 10, 300)\n",
    "data = X.reshape(-1, 1)\n",
    "target = X + 0.4 * np.random.rand(len(X))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.plot(data, target)\n",
    "plt.xlabel('输入')\n",
    "plt.ylabel('输出')\n",
    "plt.show()\n",
    "#第二步：数据集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, train_size=0.98)\n",
    "#第三步：选择并训练模型\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "regr_1 = DecisionTreeRegressor(max_depth=20)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "regr_2 = AdaBoostRegressor(base_estimator=SVR(kernel='rbf'), n_estimators=50)\n",
    "regr_3 = SVR(kernel='rbf')\n",
    "regr_1.fit(X_train, y_train)\n",
    "regr_2.fit(X_train, y_train)\n",
    "regr_3.fit(X_train, y_train)\n",
    "#第四步：结果预测\n",
    "y_pred1 = regr_1.predict(X_test)\n",
    "y_pred2 = regr_2.predict(X_test)\n",
    "y_pred3 = regr_3.predict(X_test)\n",
    "#输出结果\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('###############原始数据##################')\n",
    "print(y_test)\n",
    "print('###############决策树预测################')\n",
    "print(y_pred1)\n",
    "print(mean_squared_error(y_test, y_pred1))\n",
    "print('############Adaboost+SVR#################')\n",
    "print(y_pred2)\n",
    "print(mean_squared_error(y_test, y_pred2))\n",
    "print('##################SVR####################')\n",
    "print(y_pred3)\n",
    "print(mean_squared_error(y_test, y_pred3))\n"
   ],
   "id": "856c17421c7d055d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
